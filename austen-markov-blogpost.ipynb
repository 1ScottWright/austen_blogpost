{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Replication Percentage of Text Generation Using an n-gram Seed and Markov Chains on Sense and Sensibility for Various Levels of n.\n",
    "\n",
    "Inspired by a local lecture to the Atlanta DSI class given by Caroline Schmitt.  \n",
    "\n",
    "For exmaple, picking an n-gram at random, randomly pick the next word in the corpus using a Markov chain.  After 75 words are generated, check to see if those 75 words, in order, are present in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sense and Sensibility as Our Corpus\n",
    "## Remove punctuation and numbers\n",
    "## Make all words lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_num = ['\\n', '!', \"[\", \"]\",  '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '>', '?']\n",
    "\n",
    "corpus = gutenberg.raw('austen-sense.txt')\n",
    "\n",
    "for each in punct_num:\n",
    "    corpus = corpus.replace(each,' ')\n",
    "\n",
    "corpus = corpus.lower()\n",
    "corpus = corpus.split()\n",
    "normal_text = ' '.join(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o', 'k', 't', 'x', 'u', 'm', 'n', 'e', ' ', 'j', 'w', 'p', 'f', 'v', 's', 'q', 'c', 'a', 'y', 'b', 'z', 'l', 'g', 'h', 'i', 'd', 'r'}\n"
     ]
    }
   ],
   "source": [
    "print(set(normal_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make-pairs generator function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(corpus):\n",
    "    for i in range(len(corpus)):\n",
    "        yield (corpus[i-3]+' '+corpus[i-2], corpus[i-1]+' '+corpus[i])\n",
    "\n",
    "# note the initial values are negative which will cause the text to wrap upon itself.\n",
    "# ie, the last two words \"the end\" will be paired with the first two words \"sense and\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = make_pairs(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate word dictionary:\n",
    "\n",
    "Create a dictionary such that the keys are each n-gram in the corpus and the word that follows is placed in a list of values.  This dictionary will then be used to generate text by looking up the key and then randomly finding the next two words that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "\n",
    "for word1, word2 in pairs:\n",
    "    if word1 in word_dict.keys():\n",
    "        word_dict[word1].append(word2)\n",
    "    else:\n",
    "        word_dict[word1] = [word2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate new text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 0.0366\n"
     ]
    }
   ],
   "source": [
    "n_iter = 5        # change this to change the length of the markov chain\n",
    "\n",
    "n = 0\n",
    "\n",
    "for j in range(10000):\n",
    "#    first_word_position = 30 \n",
    "    first_word_position = np.random.choice(len(corpus))\n",
    "\n",
    "    first_ngram = corpus[first_word_position]+ ' ' + corpus[first_word_position+1]   \n",
    "    chain = [first_ngram]\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        most_recent_word = chain[-1]\n",
    "        next_ngram = np.random.choice(word_dict[most_recent_word])\n",
    "        chain.append(next_ngram)\n",
    "\n",
    "\n",
    "    extract = ' '.join(chain)\n",
    "    if extract in normal_text:\n",
    "        n+=1\n",
    "print(n, n/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed values of n (ie, probability that the text will self-generate) with various sizes of Markov chains\n",
    "\n",
    ">  Keeping starting point at word 30\n",
    "\n",
    "    > n / n_iter / x_bar  \n",
    "    > 2 / 10000 / 100%  \n",
    "    > 3 / 10000 / 100%  \n",
    "    > 4 / 10000 / 100%  \n",
    "    > 5 / 221 / 2.11%  \n",
    "    > 6 / 49 / 0.49%  \n",
    "    > 7 / 17 / 0.17%  \n",
    "    > 8 / 1 / 0.01%  \n",
    "    > 9 / 0 / 0.00%  \n",
    "\n",
    "> And keeping the length of the chain at 5 but selecting the starting 2-gram at random:  \n",
    "    > 5 / 434 / 4.34%  \n",
    "    > 5 / 385 / 3.85%  \n",
    "    > 5 / 372 / 3.72%  \n",
    "    > 5 / 389 / 3.89%  \n",
    "    > 5 / 366 / 3.66%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I was going to quit with the work above but the results of the random starting begged for one bit of analysis.  What does the mean and standard deviation look like for a random starting point and Markov chain of length 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "#  This takes quite a while to run....\n",
    "\n",
    "'''\n",
    "successes = []\n",
    "for k in range(200):\n",
    "    print(k)\n",
    "    n_iter = 5        # change this to change the length of the markov chain\n",
    "    n = 0\n",
    "\n",
    "    for j in range(10000):\n",
    "    #    first_word_position = 30 \n",
    "        first_word_position = np.random.choice(len(corpus))-1\n",
    "\n",
    "        first_ngram = corpus[first_word_position]+ ' ' + corpus[first_word_position+1]   \n",
    "        chain = [first_ngram]\n",
    "\n",
    "        for i in range(n_iter):\n",
    "            most_recent_word = chain[-1]\n",
    "            next_ngram = np.random.choice(word_dict[most_recent_word])\n",
    "            chain.append(next_ngram)\n",
    "\n",
    "\n",
    "        extract = ' '.join(chain)\n",
    "        if extract in normal_text:\n",
    "            n+=1\n",
    "    successes.append(n)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389.425"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.512276332207232"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
